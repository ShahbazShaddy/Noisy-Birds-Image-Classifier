{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"widgets":{"application/vnd.jupyter.widget-state+json":{"70626ca5be6c4475b0c569f368732f02":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_827e50b4bbb041518ead3f6357134805","IPY_MODEL_7e98c33155064880b8b6381b4e9f9581","IPY_MODEL_acc30545c48d4c4382d1032347beed05"],"layout":"IPY_MODEL_e3868055b4e743bcb9c596a7f15c1699"}},"827e50b4bbb041518ead3f6357134805":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fdf2a204ffc149f7ae57252fcb91b133","placeholder":"​","style":"IPY_MODEL_abb09b617ee5477fa1f0ec6e3db27f26","value":"Fetching 2 files: 100%"}},"7e98c33155064880b8b6381b4e9f9581":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4810d2e048fd4c3cb6b76f225b01a243","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b49414dfaa1241818d5ef1b369f7bbb7","value":2}},"acc30545c48d4c4382d1032347beed05":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_254caae9e0dc44e8ba40c4410ef22e7b","placeholder":"​","style":"IPY_MODEL_9348e5c1b18f4e12a3920ef21feaf596","value":" 2/2 [00:00&lt;00:00,  5.65it/s]"}},"e3868055b4e743bcb9c596a7f15c1699":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fdf2a204ffc149f7ae57252fcb91b133":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"abb09b617ee5477fa1f0ec6e3db27f26":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4810d2e048fd4c3cb6b76f225b01a243":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b49414dfaa1241818d5ef1b369f7bbb7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"254caae9e0dc44e8ba40c4410ef22e7b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9348e5c1b18f4e12a3920ef21feaf596":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6c02c5588e534318bb67cf98e2a95e0f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c1a81a25be83473fa67fe8858a4a58e8","IPY_MODEL_e02cc3fb983e4b4591c63cff937360d8","IPY_MODEL_a057b85469494eb8b064972d0086a031"],"layout":"IPY_MODEL_7ca254aff34b40f5abe1dc0ed1c29a8b"}},"c1a81a25be83473fa67fe8858a4a58e8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_db4788d418f843c79fb11c3a93395193","placeholder":"​","style":"IPY_MODEL_b2575715a253400fbcdcc82b1f2c3456","value":".gitattributes: 100%"}},"e02cc3fb983e4b4591c63cff937360d8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_736805aab21f44f7889596fc9333c577","max":2419,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6792596743944c5fa2ccf04c0fc760a9","value":2419}},"a057b85469494eb8b064972d0086a031":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_accdc8c3042c43c0ac6d7cb9976d8889","placeholder":"​","style":"IPY_MODEL_da5a6e7df01c464ca5c220a0d80d420c","value":" 2.42k/2.42k [00:00&lt;00:00, 156kB/s]"}},"7ca254aff34b40f5abe1dc0ed1c29a8b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db4788d418f843c79fb11c3a93395193":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2575715a253400fbcdcc82b1f2c3456":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"736805aab21f44f7889596fc9333c577":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6792596743944c5fa2ccf04c0fc760a9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"accdc8c3042c43c0ac6d7cb9976d8889":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"da5a6e7df01c464ca5c220a0d80d420c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"72df6ce6146e4dcda57f2868e5ba2171":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_64df60cee16a4552a5ce77daf7ee950f","IPY_MODEL_9801170ef5b64fb88cf6696f4e8e5ac7","IPY_MODEL_060b1b9fdec14fe884e201640b7812f3"],"layout":"IPY_MODEL_83a22455ed3b4df2b9f252929c02fe4e"}},"64df60cee16a4552a5ce77daf7ee950f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d621b41077b74887a20240bd4e840055","placeholder":"​","style":"IPY_MODEL_ab62c0d25d634d0a8eff709a5ea12661","value":"Noisy_birds.zip: 100%"}},"9801170ef5b64fb88cf6696f4e8e5ac7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9e98e0137c3d40518fa0d6b3f0bf96b2","max":7981856,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f78e2341af5c496ca730108973332974","value":7981856}},"060b1b9fdec14fe884e201640b7812f3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2c3b4212175a4f99a6f6e7d1480971e2","placeholder":"​","style":"IPY_MODEL_ddfcf52499814792864f6dc76fa4d6c7","value":" 7.98M/7.98M [00:00&lt;00:00, 71.4MB/s]"}},"83a22455ed3b4df2b9f252929c02fe4e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d621b41077b74887a20240bd4e840055":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab62c0d25d634d0a8eff709a5ea12661":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9e98e0137c3d40518fa0d6b3f0bf96b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f78e2341af5c496ca730108973332974":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2c3b4212175a4f99a6f6e7d1480971e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ddfcf52499814792864f6dc76fa4d6c7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Problem Definition\n\n\n\nWe are addressing an **image classification problem** with four distinct categories: *budgie*, *rubber duck*, *canary*, and *duckling*. The dataset consists of both **labeled** and **unlabeled images**. While the labeled data offers ground truth for model training, a significant portion of the dataset remains unlabeled, adding complexity to the task.\n\n\n\nThe objective is to develop a model that can leverage both the labeled and unlabeled data to enhance performance. The challenge lies in effectively utilizing the unlabeled data to improve classification accuracy and robustness.\n\n\n\n### Requirements:\n\n- The model must be implemented using **`torch`** and **`torchvision`** only (no other deep learning libraries are allowed for the model architecture).\n\n- The main class for the model must be named <font color='red'>**`Model`**</font>, and participants <font color='red'>**must not change this name**</font>.\n\n- Do not change the init function inside the **`Model`** class.\n\n- The size of your model should not exceed 70 MB.\n\n- Instantiating your model must not require any parameters.\n","metadata":{"id":"vzwgX35pdBr9"}},{"cell_type":"code","source":"# from datasets import load_dataset\n\nfrom torch.utils.data import Dataset,DataLoader\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom sklearn.metrics import f1_score\nfrom torchvision import models, transforms\nimport os\nimport sys\nfrom huggingface_hub import snapshot_download\nfrom PIL import Image\nfrom typing import Tuple, List\nimport random\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau","metadata":{"execution":{"iopub.status.busy":"2025-08-19T15:08:53.671760Z","iopub.execute_input":"2025-08-19T15:08:53.672084Z","iopub.status.idle":"2025-08-19T15:09:00.295666Z","shell.execute_reply.started":"2025-08-19T15:08:53.672046Z","shell.execute_reply":"2025-08-19T15:09:00.294850Z"},"id":"kSAZlOwfSqw2","trusted":true},"outputs":[],"execution_count":1},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\nprint(device)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3ibPI-yzRqsf","outputId":"ec0bea8e-d56a-4e75-ca6d-3b248169f167","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T15:09:00.296871Z","iopub.execute_input":"2025-08-19T15:09:00.297300Z","iopub.status.idle":"2025-08-19T15:09:00.403321Z","shell.execute_reply.started":"2025-08-19T15:09:00.297273Z","shell.execute_reply":"2025-08-19T15:09:00.402612Z"}},"outputs":[{"name":"stdout","text":"cuda:0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"dataset_id = \"RayanAi/Noisy_birds\"\n\n# Set the local directory where you want to store the dataset\n\nlocal_dataset_dir = \"./Noisy_birds\"  # You can change this path to your desired location\n\n\n\n# Create the directory if it doesn't exist\n\nos.makedirs(local_dataset_dir, exist_ok=True)\n\n\n\n# Suppress the output by redirecting it to os.devnull\n\nwith open(os.devnull, 'w') as fnull:\n\n    # Save the original stdout\n\n    original_stdout = sys.stdout\n\n    try:\n\n        # Redirect stdout to devnull to suppress output\n\n        sys.stdout = fnull\n\n        # Download the dataset and store it locally\n\n        snapshot_download(repo_id=dataset_id, local_dir=local_dataset_dir, repo_type=\"dataset\")\n\n    finally:\n\n        # Restore the original stdout\n\n        sys.stdout = original_stdout\n\n\n\n# Print message when download is complete\n\nprint(\"Dataset downloaded completely.\")\n\n\n\n# Calculate and print the total size of the downloaded files\n\ntotal_size = 0\n\nfor dirpath, dirnames, filenames in os.walk(local_dataset_dir):\n\n    for f in filenames:\n\n        fp = os.path.join(dirpath, f)\n\n        total_size += os.path.getsize(fp)\n\n\n\n# Convert size to MB and print\n\nprint(f\"Total size of downloaded files: {total_size / (1024 * 1024):.2f} MB\")\n\n\n\n# Get the absolute path of the dataset directory and print it\n\ndataset_abs_path = os.path.abspath(local_dataset_dir)\n\nprint(f\"Dataset has been saved at: [{dataset_abs_path}]\")\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":289,"referenced_widgets":["70626ca5be6c4475b0c569f368732f02","827e50b4bbb041518ead3f6357134805","7e98c33155064880b8b6381b4e9f9581","acc30545c48d4c4382d1032347beed05","e3868055b4e743bcb9c596a7f15c1699","fdf2a204ffc149f7ae57252fcb91b133","abb09b617ee5477fa1f0ec6e3db27f26","4810d2e048fd4c3cb6b76f225b01a243","b49414dfaa1241818d5ef1b369f7bbb7","254caae9e0dc44e8ba40c4410ef22e7b","9348e5c1b18f4e12a3920ef21feaf596","6c02c5588e534318bb67cf98e2a95e0f","c1a81a25be83473fa67fe8858a4a58e8","e02cc3fb983e4b4591c63cff937360d8","a057b85469494eb8b064972d0086a031","7ca254aff34b40f5abe1dc0ed1c29a8b","db4788d418f843c79fb11c3a93395193","b2575715a253400fbcdcc82b1f2c3456","736805aab21f44f7889596fc9333c577","6792596743944c5fa2ccf04c0fc760a9","accdc8c3042c43c0ac6d7cb9976d8889","da5a6e7df01c464ca5c220a0d80d420c","72df6ce6146e4dcda57f2868e5ba2171","64df60cee16a4552a5ce77daf7ee950f","9801170ef5b64fb88cf6696f4e8e5ac7","060b1b9fdec14fe884e201640b7812f3","83a22455ed3b4df2b9f252929c02fe4e","d621b41077b74887a20240bd4e840055","ab62c0d25d634d0a8eff709a5ea12661","9e98e0137c3d40518fa0d6b3f0bf96b2","f78e2341af5c496ca730108973332974","2c3b4212175a4f99a6f6e7d1480971e2","ddfcf52499814792864f6dc76fa4d6c7"]},"execution":{"iopub.status.busy":"2025-08-19T15:09:00.404217Z","iopub.execute_input":"2025-08-19T15:09:00.404456Z","iopub.status.idle":"2025-08-19T15:09:01.907866Z","shell.execute_reply.started":"2025-08-19T15:09:00.404438Z","shell.execute_reply":"2025-08-19T15:09:01.907153Z"},"id":"uWJftwbhzLLQ","outputId":"37d36d5e-c7e7-4705-a515-eb2607c0437e","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8efadeb453344c4d9cb5ed29f23f2537"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Noisy_birds.zip:   0%|          | 0.00/7.98M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ba04762884b4ae9950d99e25f28469a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":".gitattributes: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc5133727d32446d93d401017a9895d7"}},"metadata":{}},{"name":"stdout","text":"Dataset downloaded completely.\nTotal size of downloaded files: 7.61 MB\nDataset has been saved at: [/kaggle/working/Noisy_birds]\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!unzip -qo ./Noisy_birds/Noisy_birds.zip -d ./Noisy_birds/","metadata":{"id":"eR8yA4cUsm0I","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T15:09:06.116256Z","iopub.execute_input":"2025-08-19T15:09:06.116561Z","iopub.status.idle":"2025-08-19T15:09:06.393796Z","shell.execute_reply.started":"2025-08-19T15:09:06.116538Z","shell.execute_reply":"2025-08-19T15:09:06.392826Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## Dataset","metadata":{"id":"ghM6Shr2Td1I"}},{"cell_type":"markdown","source":"In this part, the dataset is downloaded and needed agumentation functions are applied. You only need to define the necessary transform functions for augmentation. At the end you are provided with a train_loader, val_loader and a test_loader.","metadata":{"id":"jmF6B1C5Tgyo"}},{"cell_type":"code","source":"transform = transforms.Compose([\n\n    transforms.ToTensor(),\n\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n\n                         std=[0.229, 0.224, 0.225])\n\n])\n\n\n\ntransform_test = transforms.Compose([\n\n    transforms.ToTensor(),\n\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n\n                         std=[0.229, 0.224, 0.225])\n\n])","metadata":{"execution":{"iopub.status.busy":"2025-08-19T15:29:49.502962Z","iopub.execute_input":"2025-08-19T15:29:49.503876Z","iopub.status.idle":"2025-08-19T15:29:49.509244Z","shell.execute_reply.started":"2025-08-19T15:29:49.503844Z","shell.execute_reply":"2025-08-19T15:29:49.508277Z"},"id":"cFT6712nSqw7","trusted":true},"outputs":[],"execution_count":27},{"cell_type":"code","source":"import os\n\nimport numpy as np\n\nimport random\n\nimport torch\n\nimport torch.nn.functional as F\n\nfrom torch.utils.data import Dataset\n\n#Define the split ratio\n\nsplit_ratio = 0.6\n\n\n\n#Dataset function called\n\nclass Birddataset(Dataset):\n\n    def __init__(self, image_dir: str, allowed_classes: List, transform=None, dataset_type: str = None):\n\n        \"\"\"\n\n        Args:\n\n            image_dir (str): Directory path containing input images.\n\n            mask_dir (str): Directory path containing corresponding segmentation masks.\n\n            transform (callable): Optional transformation to be applied to both the image and the mask. . Use ToTensorV2()\n\n            dataset_type (str, optional): Type of dataset, e.g., 'Train' or 'Test'. Defaults to 'Train'.\n\n        \"\"\"\n\n        # Initialize paths and transformation\n\n        self.allowed_classes=allowed_classes\n\n        self.image_dir = image_dir\n\n        self.dataset_type = dataset_type\n\n        self.transform = transform\n\n        self.classes = [item for item in os.listdir(self.image_dir) if os.path.isdir(os.path.join(self.image_dir, item))]\n\n        self.samples=[]\n\n        for class_name in self.classes:\n\n                if class_name in allowed_classes:\n\n\n\n                    self.images = os.listdir(os.path.join(self.image_dir, class_name))\n\n                    for img in self.images:\n\n                        self.samples.append([img,class_name])\n\n\n\n        random.seed(87)\n\n        random.shuffle(self.samples)\n\n\n\n        # print(self.samples)\n\n\n\n        if dataset_type == 'Train':\n\n            self.images = self.samples[:int(len(self.samples)*split_ratio)]\n\n        elif dataset_type == 'Test':\n\n            self.images = self.samples[int(len(self.samples)*split_ratio):]\n\n        else:\n\n            self.images = self.samples\n\n\n\n    def __len__(self) -> int:\n\n        \"\"\"\n\n        Returns:\n\n            int: The total number of image-mask pairs in the designated dataset split.\n\n        \"\"\"\n\n        # Return the length of the dataset (number of images)\n\n        return len(self.images)\n\n\n\n\n\n    def __getitem__(self, index: int) -> tuple[torch.Tensor, torch.Tensor]:\n\n        \"\"\"\n\n        Args:\n\n            index (int): Index of the image-mask pair to retrieve.\n\n\n\n        Returns:\n\n            Tuple[torch.Tensor, torch.Tensor]: A tuple containing the image and its corresponding one-hot encoded mask.\n\n                - image (torch.Tensor): Transformed image tensor.\n\n                - onehot_mask (torch.Tensor): One-hot encoded mask tensor for segmentation.\n\n        \"\"\"\n\n        # Load the image and mask\n\n        image_path = os.path.join(self.image_dir,self.images[index][1],self.images[index][0])\n\n\n\n\n\n\n\n        # Load image and mask as grayscale\n\n        image = Image.open(image_path)\n\n        if self.transform:\n\n            transformed = self.transform(image)\n\n        else:\n\n            transformed = transform_test(image)\n\n\n\n        class_id = self.allowed_classes.index(self.images[index][1])\n\n\n\n        return transformed, class_id\n\n\n","metadata":{"execution":{"iopub.status.busy":"2025-08-19T15:29:51.916517Z","iopub.execute_input":"2025-08-19T15:29:51.916806Z","iopub.status.idle":"2025-08-19T15:29:51.926780Z","shell.execute_reply.started":"2025-08-19T15:29:51.916783Z","shell.execute_reply":"2025-08-19T15:29:51.926057Z"},"id":"YGAygyUiSqw7","trusted":true},"outputs":[],"execution_count":28},{"cell_type":"code","source":"train_dataset = Birddataset(\n\n    image_dir=\"./Noisy_birds\",\n\n    allowed_classes=[\"budgie\",\"canary\",\"duckling\",\"rubber duck\"],\n\n    transform=transform,\n\n\n\n    dataset_type='Train',\n\n\n\n)\n\n\n\nval_dataset = Birddataset(\n\n    image_dir= \"./Noisy_birds\",\n\n    allowed_classes=[\"budgie\",\"canary\",\"duckling\",\"rubber duck\"],\n\n    transform=transform_test,\n\n    dataset_type='Test',\n\n\n\n)\n\n\n\nunlabeled_dataset = Birddataset(\n\n    image_dir=\"./Noisy_birds\",\n\n    allowed_classes=[\"unlabeled\"],\n\n\n\n)","metadata":{"id":"B2Gdlz8Lsm0K","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T15:29:55.016561Z","iopub.execute_input":"2025-08-19T15:29:55.016846Z","iopub.status.idle":"2025-08-19T15:29:55.024280Z","shell.execute_reply.started":"2025-08-19T15:29:55.016823Z","shell.execute_reply":"2025-08-19T15:29:55.023554Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"batch_size = 128\n\nnum_workers = 2 # Change if you have beefy CPU\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,num_workers=num_workers)\n\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False,num_workers=num_workers)\n\nunlabeled_loader = torch.utils.data.DataLoader(unlabeled_dataset, batch_size=batch_size, shuffle=False,num_workers=num_workers)","metadata":{"id":"XOiOWoWxo0i5","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T15:29:57.393272Z","iopub.execute_input":"2025-08-19T15:29:57.393554Z","iopub.status.idle":"2025-08-19T15:29:57.398629Z","shell.execute_reply.started":"2025-08-19T15:29:57.393534Z","shell.execute_reply":"2025-08-19T15:29:57.397931Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"# Updated Transformations with Data Augmentation\ntransform = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(15),\n    transforms.RandomResizedCrop(128, scale=(0.8, 1.0)),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T15:29:58.339721Z","iopub.execute_input":"2025-08-19T15:29:58.340289Z","iopub.status.idle":"2025-08-19T15:29:58.345008Z","shell.execute_reply.started":"2025-08-19T15:29:58.340268Z","shell.execute_reply":"2025-08-19T15:29:58.344186Z"}},"outputs":[],"execution_count":31},{"cell_type":"markdown","source":"## CNN\n\nDefine a CNN model. It should be small enough to require less than 2GB of Vram (GPU Memmory) when using a batch size of 128.","metadata":{"id":"ObaXYhsZT8hm"}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom torchvision import models, transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.metrics import f1_score, roc_auc_score\nimport numpy as np\nimport os\nfrom PIL import Image\nfrom huggingface_hub import snapshot_download\nimport random\nimport matplotlib.pyplot as plt\nfrom typing import Tuple, List\n\n# Assuming train_loader, val_loader, device, etc., are defined as in your original notebook\n\n# Function to create different models\ndef get_model(model_name: str) -> nn.Module:\n    if model_name == 'densenet121':\n        base_model = models.densenet121(pretrained=True)\n        num_ftrs = base_model.classifier.in_features\n        base_model.classifier = nn.Linear(num_ftrs, 4)\n    elif model_name == 'resnet50':\n        base_model = models.resnet50(pretrained=True)\n        num_ftrs = base_model.fc.in_features\n        base_model.fc = nn.Linear(num_ftrs, 4)\n    elif model_name == 'efficientnet_b0':\n        base_model = models.efficientnet_b0(pretrained=True)\n        num_ftrs = base_model.classifier[1].in_features\n        base_model.classifier[1] = nn.Linear(num_ftrs, 4)\n    elif model_name == 'mobilenet_v3_large':\n        base_model = models.mobilenet_v3_large(pretrained=True)\n        num_ftrs = base_model.classifier[3].in_features\n        base_model.classifier[3] = nn.Linear(num_ftrs, 4)\n    elif model_name == 'resnet18':\n        base_model = models.resnet18(pretrained=True)\n        num_ftrs = base_model.fc.in_features\n        base_model.fc = nn.Linear(num_ftrs, 4)\n    else:\n        raise ValueError(f\"Unknown model name: {model_name}\")\n    return base_model\n\n# Training function\ndef train_model(model, train_loader, val_loader, epochs=30, lr=0.001):\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=lr)\n    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n    \n    best_val_loss = float('inf')\n    best_model_state = None\n    \n    for epoch in range(epochs):\n        model.train()\n        running_loss = 0.0\n        for inputs, labels in train_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n        \n        val_loss = 0.0\n        model.eval()\n        with torch.no_grad():\n            for inputs, labels in val_loader:\n                inputs, labels = inputs.to(device), labels.to(device)\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n                val_loss += loss.item()\n        \n        val_loss /= len(val_loader)\n        scheduler.step(val_loss)\n        \n        print(f\"Epoch {epoch+1}/{epochs}, Training Loss: {running_loss/len(train_loader):.4f}, Validation Loss: {val_loss:.4f}\")\n        \n        if val_loss < best_val_loss:\n            best_val_loss = val_loss\n            best_model_state = model.state_dict()\n    \n    model.load_state_dict(best_model_state)\n    return model, best_val_loss\n\n# Evaluation function with F1, Accuracy, and AUC\ndef evaluate_model(model, val_loader):\n    model.eval()\n    all_preds = []\n    all_labels = []\n    all_probs = []\n    with torch.no_grad():\n        for inputs, labels in val_loader:\n            inputs = inputs.to(device)\n            outputs = model(inputs)\n            probs = torch.softmax(outputs, dim=1)  # Get probabilities for AUC\n            _, preds = torch.max(outputs, 1)\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n            all_probs.extend(probs.cpu().numpy())\n    \n    # Calculate F1 score and accuracy\n    f1 = f1_score(all_labels, all_preds, average='macro')\n    accuracy = np.mean(np.array(all_preds) == np.array(all_labels))\n    \n    # Calculate AUC score (one-vs-rest for multi-class)\n    try:\n        auc = roc_auc_score(all_labels, all_probs, multi_class='ovr')\n    except ValueError:\n        auc = float('nan')  # In case AUC calculation fails due to class imbalance or other issues\n    \n    print(f\"F1 Score: {f1:.4f}, Accuracy: {accuracy:.4f}, AUC: {auc:.4f}\")\n    print(\"Predictions:\", all_preds)\n    print(\"True Labels:\", all_labels)\n    return f1, accuracy, auc\n\n# List of models to try\nmodel_names = ['densenet121', 'resnet50', 'efficientnet_b0', 'mobilenet_v3_large', 'resnet18']\n\n# Dictionary to store results\nresults = {}\n\n# Train and evaluate each model\nfor model_name in model_names:\n    print(f\"\\nTraining {model_name}...\")\n    model = get_model(model_name).to(device)\n    trained_model, val_loss = train_model(model, train_loader, val_loader, epochs=30)\n    f1, acc, auc = evaluate_model(trained_model, val_loader)\n    results[model_name] = {'f1': f1, 'acc': acc, 'auc': auc, 'val_loss': val_loss}\n    # Save each model\n    torch.save(trained_model.state_dict(), f\"{model_name}_model.pth\")\n\n# Choose the best model based on F1 score\nbest_model_name = max(results, key=lambda k: results[k]['f1'])\nbest_f1 = results[best_model_name]['f1']\nprint(f\"\\nBest model: {best_model_name} with F1 Score: {best_f1:.4f}, Accuracy: {results[best_model_name]['acc']:.4f}, AUC: {results[best_model_name]['auc']:.4f}\")\n\n# Define the final Model class with the best model\nclass Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n        self.model = get_model(best_model_name)\n        self.model.load_state_dict(torch.load(f\"{best_model_name}_model.pth\"))\n\n    def forward(self, x):\n        return self.model(x)\n\n# Save the best model\ntorch.save(Model().cpu().state_dict(), \"best_model.pth\")","metadata":{"execution":{"iopub.status.busy":"2025-08-19T15:30:01.455278Z","iopub.execute_input":"2025-08-19T15:30:01.455909Z"},"id":"ViHGmKCuSqw8","trusted":true},"outputs":[{"name":"stdout","text":"\nTraining densenet121...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/30, Training Loss: 1.4647, Validation Loss: 1.4107\nEpoch 2/30, Training Loss: 0.2483, Validation Loss: 1.3515\nEpoch 3/30, Training Loss: 0.0540, Validation Loss: 1.3133\nEpoch 4/30, Training Loss: 0.0200, Validation Loss: 1.2333\nEpoch 5/30, Training Loss: 0.0103, Validation Loss: 1.1474\nEpoch 6/30, Training Loss: 0.0060, Validation Loss: 1.0629\nEpoch 7/30, Training Loss: 0.0039, Validation Loss: 0.9865\nEpoch 8/30, Training Loss: 0.0027, Validation Loss: 0.9280\nEpoch 9/30, Training Loss: 0.0019, Validation Loss: 0.8879\nEpoch 10/30, Training Loss: 0.0014, Validation Loss: 0.8667\nEpoch 11/30, Training Loss: 0.0011, Validation Loss: 0.8588\nEpoch 12/30, Training Loss: 0.0009, Validation Loss: 0.8641\nEpoch 13/30, Training Loss: 0.0007, Validation Loss: 0.8770\nEpoch 14/30, Training Loss: 0.0006, Validation Loss: 0.8940\nEpoch 15/30, Training Loss: 0.0005, Validation Loss: 0.9130\nEpoch 16/30, Training Loss: 0.0005, Validation Loss: 0.9332\nEpoch 17/30, Training Loss: 0.0004, Validation Loss: 0.9553\nEpoch 18/30, Training Loss: 0.0004, Validation Loss: 0.9430\nEpoch 19/30, Training Loss: 0.0004, Validation Loss: 0.9358\nEpoch 20/30, Training Loss: 0.0004, Validation Loss: 0.9318\nEpoch 21/30, Training Loss: 0.0004, Validation Loss: 0.9287\nEpoch 22/30, Training Loss: 0.0003, Validation Loss: 0.9269\nEpoch 23/30, Training Loss: 0.0003, Validation Loss: 0.9249\nEpoch 24/30, Training Loss: 0.0003, Validation Loss: 0.9218\nEpoch 25/30, Training Loss: 0.0003, Validation Loss: 0.9189\nEpoch 26/30, Training Loss: 0.0003, Validation Loss: 0.9162\nEpoch 27/30, Training Loss: 0.0003, Validation Loss: 0.9145\nEpoch 28/30, Training Loss: 0.0003, Validation Loss: 0.9134\nEpoch 29/30, Training Loss: 0.0003, Validation Loss: 0.9125\nEpoch 30/30, Training Loss: 0.0003, Validation Loss: 0.9115\nF1 Score: 0.7535, Accuracy: 0.7500, AUC: 0.9216\nPredictions: [1, 0, 3, 1, 1, 1, 1, 3, 3, 3, 3, 2, 2, 1, 2, 2, 2, 1, 3, 1, 3, 3, 2, 1, 0, 1, 2, 1, 0, 1, 2, 2, 2, 0, 0, 3, 1, 3, 0, 3, 0, 0, 0, 3, 2, 2, 3, 0, 0, 3, 0, 3, 1, 2, 0, 1, 3, 2, 0, 3]\nTrue Labels: [1, 0, 3, 1, 1, 3, 0, 3, 3, 3, 3, 2, 0, 0, 0, 2, 2, 1, 3, 1, 0, 1, 2, 0, 1, 1, 2, 0, 0, 1, 2, 2, 1, 0, 0, 3, 1, 3, 0, 3, 0, 0, 0, 3, 2, 2, 3, 1, 0, 3, 1, 3, 1, 2, 1, 0, 3, 2, 0, 3]\n\nTraining resnet50...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/30, Training Loss: 1.5784, Validation Loss: 2.7072\nEpoch 2/30, Training Loss: 0.6803, Validation Loss: 1.7645\nEpoch 3/30, Training Loss: 0.1112, Validation Loss: 2.1827\nEpoch 4/30, Training Loss: 0.0097, Validation Loss: 3.2508\nEpoch 5/30, Training Loss: 0.0025, Validation Loss: 4.7228\nEpoch 6/30, Training Loss: 0.0012, Validation Loss: 6.0738\nEpoch 7/30, Training Loss: 0.0009, Validation Loss: 7.1014\nEpoch 8/30, Training Loss: 0.0007, Validation Loss: 7.6567\nEpoch 9/30, Training Loss: 0.0005, Validation Loss: 6.7316\nEpoch 10/30, Training Loss: 0.0005, Validation Loss: 5.8794\nEpoch 11/30, Training Loss: 0.0005, Validation Loss: 5.1335\nEpoch 12/30, Training Loss: 0.0004, Validation Loss: 4.4860\nEpoch 13/30, Training Loss: 0.0004, Validation Loss: 3.9496\nEpoch 14/30, Training Loss: 0.0004, Validation Loss: 3.5022\nEpoch 15/30, Training Loss: 0.0003, Validation Loss: 3.1088\nEpoch 16/30, Training Loss: 0.0003, Validation Loss: 2.7899\nEpoch 17/30, Training Loss: 0.0003, Validation Loss: 2.5624\nEpoch 18/30, Training Loss: 0.0003, Validation Loss: 2.4078\nEpoch 19/30, Training Loss: 0.0003, Validation Loss: 2.2954\nEpoch 20/30, Training Loss: 0.0003, Validation Loss: 2.2096\nEpoch 21/30, Training Loss: 0.0003, Validation Loss: 2.1400\nEpoch 22/30, Training Loss: 0.0003, Validation Loss: 2.0848\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}